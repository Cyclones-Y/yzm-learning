{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "在PyTorch中，CPU和GPU可以用torch.device('cpu') 和torch.device('cuda')表示。 应该注意的是，cpu设备意味着所有物理CPU和内存， 这意味着PyTorch的计算将尝试使用所有CPU核心。 然而，gpu设备只代表一个卡和相应的显存。 如果有多个GPU，我们使用torch.device(f'cuda:{i}') 来表示第\n",
    "块GPU（\n",
    "从0开始）。 另外，cuda:0和cuda是等价的。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c1ae9bc9b3cc1f2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "(device(type='cpu'), device(type='cuda'), device(type='cuda', index=1))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:42:55.181464100Z",
     "start_time": "2023-12-21T08:42:54.384486500Z"
    }
   },
   "id": "ad771750e83b2a73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以查询可用gpu的数量。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40c49c672388f81e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:43:22.009050800Z",
     "start_time": "2023-12-21T08:43:21.993399100Z"
    }
   },
   "id": "c592e3a003828474"
  },
  {
   "cell_type": "markdown",
   "source": [
    "现在我们定义了两个方便的函数， 这两个函数允许我们在不存在所需所有GPU的情况下运行代码。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f42a226ff78c4013"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[device(type='cpu')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_gpu(i=0): #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "def try_all_gpu():#@save\n",
    "    devices = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "    return devices if devices else [(torch.device('cpu'))]\n",
    "    \n",
    "try_all_gpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:01:13.946074Z",
     "start_time": "2023-12-21T09:01:13.876580100Z"
    }
   },
   "id": "8198891ab186fd03"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "### 张量与GPU"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:01:26.662669300Z",
     "start_time": "2023-12-21T09:01:26.643728600Z"
    }
   },
   "id": "87445138a4563eb3"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:07:34.262730900Z",
     "start_time": "2023-12-21T09:07:34.242348500Z"
    }
   },
   "id": "bdc27cc1b40fea48"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,3,device=try_gpu())\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:08:37.338697200Z",
     "start_time": "2023-12-21T09:08:37.307065600Z"
    }
   },
   "id": "6cb9f71058621948"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.9935, -15.2034,  13.8756,  ...,  -5.0767, -10.0420,  23.5316],\n",
      "        [-11.8720,   7.4875,   6.6112,  ...,  -9.3314,  -3.6739,  15.5573],\n",
      "        [ 16.6162, -11.0890,  -1.7364,  ..., -29.5692, -13.4406,  -7.1624],\n",
      "        ...,\n",
      "        [ -9.5134, -13.9708,   5.5438,  ...,   6.6150,  14.4579,   2.3029],\n",
      "        [-12.3733,  10.2774,  -9.6445,  ...,   7.1449,  18.8244, -12.8349],\n",
      "        [  4.3504,  11.9398,  -7.0344,  ..., -14.4520,  -4.3539, -10.1885]])\n"
     ]
    }
   ],
   "source": [
    "matrices1 = torch.randn(100,100)\n",
    "matrices2 = torch.randn(100,100)\n",
    "matrices3 = (torch.mm(matrices1, matrices2)) \n",
    "print(matrices3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T09:26:36.437675600Z",
     "start_time": "2023-12-21T09:26:36.422050400Z"
    }
   },
   "id": "4b2fb1abd06020d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bca504279e10405f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
